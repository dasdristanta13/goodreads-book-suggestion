{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\goodreads\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm.autonotebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"../data/file_part_1_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['isbn', 'text_reviews_count', 'series', 'country_code', 'language_code',\n",
       "       'popular_shelves', 'asin', 'is_ebook', 'average_rating', 'kindle_asin',\n",
       "       'similar_books', 'description', 'format', 'link', 'authors',\n",
       "       'publisher', 'num_pages', 'publication_day', 'isbn13',\n",
       "       'publication_month', 'edition_information', 'publication_year', 'url',\n",
       "       'image_url', 'book_id', 'ratings_count', 'work_id', 'title',\n",
       "       'title_without_series'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/book_id_review_80793.pkl','rb') as b_r:\n",
    "    book_review = pickle.load(b_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1[~df_1.description.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1[~df_1.publication_year.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1[\"book_id\"] = df_1[\"book_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_df = pd.DataFrame({\"book_id\":book_review.keys(),\"Review\":book_review.values()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_rev = pd.merge(df_1,rev_df,on=[\"book_id\"],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_rev.to_csv(\"../data/file_part_1_with_review.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_reviews(reviews, book_description, embedding_model, top_k=5):\n",
    "#     # Embed the book description\n",
    "#     book_embedding = embedding_model.encode([book_description])[0]\n",
    "    \n",
    "#     # Embed all reviews\n",
    "#     review_embeddings = embedding_model.encode(reviews)\n",
    "    \n",
    "#     # Calculate cosine similarity between book description and reviews\n",
    "#     similarities = cosine_similarity([book_embedding], review_embeddings)[0]\n",
    "    \n",
    "#     # Get indices of top-k most similar reviews\n",
    "#     top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "    \n",
    "#     # Return top-k most relevant reviews\n",
    "#     return [reviews[i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize embedding model\n",
    "# embedding_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_top_rev = pd.read_csv(\"../data/file_part_1_with_top_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 67651/67651 [01:01<00:00, 1107.99it/s]\n"
     ]
    }
   ],
   "source": [
    "for _, row in tqdm(df_1_top_rev.iterrows(), total=len(df_1_rev), desc=\"Processing rows\"):\n",
    "    G.add_node(row['book_id'], type='book', title=row['title'],\n",
    "                   isbn=row['isbn'], isbn13=row['isbn13'],\n",
    "                   average_rating=row['average_rating'],\n",
    "                   ratings_count=row['ratings_count'],\n",
    "                   text_reviews_count=row['text_reviews_count'],\n",
    "                   num_pages=row['num_pages'],\n",
    "                   description=row['description'],\n",
    "                #    language_code=row['language_code'],\n",
    "                   country_code=row['country_code'],\n",
    "                   embedding=None)\n",
    "    authors = eval(row['authors'])\n",
    "    for author in authors:\n",
    "        # print(author)\n",
    "        G.add_node(author.get('author_id'), type='author')\n",
    "        G.add_edge(row['book_id'], author.get('author_id'), relation='written_by')\n",
    "            # Add publisher node and edge\n",
    "    if pd.notna(row['publisher']):\n",
    "        G.add_node(row['publisher'], type='publisher')\n",
    "        G.add_edge(row['book_id'], row['publisher'], relation='published_by')\n",
    "    if pd.notna(row['publication_year']):\n",
    "        G.add_node(row['publication_year'], type='year')\n",
    "        G.add_edge(row['book_id'], row['publication_year'], relation='published_in_year')\n",
    "\n",
    "    # Add format node and edge\n",
    "    if pd.notna(row['format']):\n",
    "        G.add_node(row['format'], type='format')\n",
    "        G.add_edge(row['book_id'], row['format'], relation='available_in')\n",
    "        # Add similar books edges\n",
    "    if len(row['similar_books'])>0:\n",
    "        similar_books = row['similar_books']\n",
    "        for similar_book in similar_books:\n",
    "            if similar_book in df_1['book_id']:\n",
    "                G.add_edge(row['book_id'], similar_book, relation='similar_to')\n",
    "            # Process reviews\n",
    "    if 'Top_Reviews' in row:\n",
    "        try:\n",
    "            top_reviews = eval(row[\"Top_Reviews\"])\n",
    "            for i, review in enumerate(top_reviews):\n",
    "                review_node = f\"{row['book_id']}_review_{i}\"\n",
    "                G.add_node(review_node, type='review', content=review)\n",
    "                G.add_edge(row['book_id'], review_node, relation='has_review')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def validate_graph(G, df):\n",
    "    \"\"\"\n",
    "    Main function to run all validation checks\n",
    "    \"\"\"\n",
    "    print(\"Starting graph validation...\")\n",
    "    \n",
    "    check_node_count(G, df)\n",
    "    check_book_attributes(G, df)\n",
    "    check_author_connections(G, df)\n",
    "    check_publisher_connections(G, df)\n",
    "    check_year_connections(G, df)\n",
    "    check_format_connections(G, df)\n",
    "    check_similar_books(G, df)\n",
    "    check_review_connections(G)\n",
    "    check_graph_connectivity(G)\n",
    "    \n",
    "    print(\"Graph validation complete.\")\n",
    "\n",
    "def check_node_count(G, df):\n",
    "    \"\"\"\n",
    "    Check if the number of nodes in the graph matches the expected count\n",
    "    \"\"\"\n",
    "    expected_book_count = len(df)\n",
    "    actual_book_count = len([n for n in G.nodes if G.nodes[n]['type'] == 'book'])\n",
    "    \n",
    "    print(f\"Expected book count: {expected_book_count}\")\n",
    "    print(f\"Actual book count: {actual_book_count}\")\n",
    "    if expected_book_count != actual_book_count:\n",
    "        print(f\"WARNING: Mismatch in book count. Expected {expected_book_count}, got {actual_book_count}\")\n",
    "\n",
    "def check_book_attributes(G, df):\n",
    "    \"\"\"\n",
    "    Check if book nodes have all required attributes\n",
    "    \"\"\"\n",
    "    required_attributes = ['title', 'isbn', 'isbn13', 'average_rating', 'ratings_count', \n",
    "                           'text_reviews_count', 'num_pages', 'description', 'country_code']\n",
    "    \n",
    "    sample_books = random.sample(list(df['book_id']), min(100, len(df)))\n",
    "    missing_attributes = {}\n",
    "    \n",
    "    for book_id in sample_books:\n",
    "        node_data = G.nodes[book_id]\n",
    "        for attr in required_attributes:\n",
    "            if attr not in node_data:\n",
    "                if book_id not in missing_attributes:\n",
    "                    missing_attributes[book_id] = []\n",
    "                missing_attributes[book_id].append(attr)\n",
    "    \n",
    "    if missing_attributes:\n",
    "        print(\"WARNING: Some books are missing attributes:\")\n",
    "        for book_id, attrs in missing_attributes.items():\n",
    "            print(f\"Book {book_id} is missing: {', '.join(attrs)}\")\n",
    "    else:\n",
    "        print(\"All sampled books have the required attributes.\")\n",
    "\n",
    "def check_author_connections(G, df):\n",
    "    \"\"\"\n",
    "    Check if all books are connected to their authors\n",
    "    \"\"\"\n",
    "    sample_books = random.sample(list(df['book_id']), min(100, len(df)))\n",
    "    missing_connections = []\n",
    "    \n",
    "    for book_id in sample_books:\n",
    "        authors = eval(df[df['book_id'] == book_id]['authors'].iloc[0])\n",
    "        for author in authors:\n",
    "            author_id = author['author_id']\n",
    "            if not G.has_edge(book_id, author_id):\n",
    "                missing_connections.append((book_id, author_id))\n",
    "    \n",
    "    if missing_connections:\n",
    "        print(\"WARNING: Some books are not connected to their authors:\")\n",
    "        for book_id, author_id in missing_connections:\n",
    "            print(f\"Missing edge between book {book_id} and author {author_id}\")\n",
    "    else:\n",
    "        print(\"All sampled books are correctly connected to their authors.\")\n",
    "\n",
    "def check_publisher_connections(G, df):\n",
    "    \"\"\"\n",
    "    Check if books are connected to their publishers\n",
    "    \"\"\"\n",
    "    sample_books = random.sample(list(df[df['publisher'].notna()]['book_id']), min(100, len(df)))\n",
    "    missing_connections = []\n",
    "    \n",
    "    for book_id in sample_books:\n",
    "        publisher = df[df['book_id'] == book_id]['publisher'].iloc[0]\n",
    "        if not G.has_edge(book_id, publisher):\n",
    "            missing_connections.append((book_id, publisher))\n",
    "    \n",
    "    if missing_connections:\n",
    "        print(\"WARNING: Some books are not connected to their publishers:\")\n",
    "        for book_id, publisher in missing_connections:\n",
    "            print(f\"Missing edge between book {book_id} and publisher {publisher}\")\n",
    "    else:\n",
    "        print(\"All sampled books are correctly connected to their publishers.\")\n",
    "\n",
    "def check_year_connections(G, df):\n",
    "    \"\"\"\n",
    "    Check if books are connected to their publication years\n",
    "    \"\"\"\n",
    "    sample_books = random.sample(list(df[df['publication_year'].notna()]['book_id']), min(100, len(df)))\n",
    "    missing_connections = []\n",
    "    \n",
    "    for book_id in sample_books:\n",
    "        year = df[df['book_id'] == book_id]['publication_year'].iloc[0]\n",
    "        if not G.has_edge(book_id, year):\n",
    "            missing_connections.append((book_id, year))\n",
    "    \n",
    "    if missing_connections:\n",
    "        print(\"WARNING: Some books are not connected to their publication years:\")\n",
    "        for book_id, year in missing_connections:\n",
    "            print(f\"Missing edge between book {book_id} and year {year}\")\n",
    "    else:\n",
    "        print(\"All sampled books are correctly connected to their publication years.\")\n",
    "\n",
    "def check_format_connections(G, df):\n",
    "    \"\"\"\n",
    "    Check if books are connected to their formats\n",
    "    \"\"\"\n",
    "    sample_books = random.sample(list(df[df['format'].notna()]['book_id']), min(100, len(df)))\n",
    "    missing_connections = []\n",
    "    \n",
    "    for book_id in sample_books:\n",
    "        format = df[df['book_id'] == book_id]['format'].iloc[0]\n",
    "        if not G.has_edge(book_id, format):\n",
    "            missing_connections.append((book_id, format))\n",
    "    \n",
    "    if missing_connections:\n",
    "        print(\"WARNING: Some books are not connected to their formats:\")\n",
    "        for book_id, format in missing_connections:\n",
    "            print(f\"Missing edge between book {book_id} and format {format}\")\n",
    "    else:\n",
    "        print(\"All sampled books are correctly connected to their formats.\")\n",
    "\n",
    "def check_similar_books(G, df):\n",
    "    \"\"\"\n",
    "    Check if books are connected to their similar books\n",
    "    \"\"\"\n",
    "    sample_books = random.sample(list(df[df['similar_books'].apply(lambda x: len(x) > 0)]['book_id']), min(100, len(df)))\n",
    "    missing_connections = []\n",
    "    \n",
    "    for book_id in sample_books:\n",
    "        similar_books = df[df['book_id'] == book_id]['similar_books'].iloc[0]\n",
    "        for similar_book in similar_books:\n",
    "            if similar_book in df['book_id'].values and not G.has_edge(book_id, similar_book):\n",
    "                missing_connections.append((book_id, similar_book))\n",
    "    \n",
    "    if missing_connections:\n",
    "        print(\"WARNING: Some books are not connected to their similar books:\")\n",
    "        for book_id, similar_book in missing_connections:\n",
    "            print(f\"Missing edge between book {book_id} and similar book {similar_book}\")\n",
    "    else:\n",
    "        print(\"All sampled books are correctly connected to their similar books.\")\n",
    "\n",
    "def check_review_connections(G):\n",
    "    \"\"\"\n",
    "    Check if books with reviews have the correct number of review connections\n",
    "    \"\"\"\n",
    "    book_nodes = [n for n in G.nodes if G.nodes[n]['type'] == 'book']\n",
    "    sample_books = random.sample(book_nodes, min(100, len(book_nodes)))\n",
    "    books_with_excess_reviews = []\n",
    "    \n",
    "    for book_id in sample_books:\n",
    "        review_edges = [e for e in G.edges(book_id, data=True) if e[2]['relation'] == 'has_review']\n",
    "        if len(review_edges) > 5:\n",
    "            books_with_excess_reviews.append((book_id, len(review_edges)))\n",
    "    \n",
    "    if books_with_excess_reviews:\n",
    "        print(\"WARNING: Some books have more than 5 review connections:\")\n",
    "        for book_id, review_count in books_with_excess_reviews:\n",
    "            print(f\"Book {book_id} has {review_count} review connections\")\n",
    "    else:\n",
    "        print(\"All sampled books have 5 or fewer review connections.\")\n",
    "\n",
    "def check_graph_connectivity(G):\n",
    "    \"\"\"\n",
    "    Check if the graph is connected\n",
    "    \"\"\"\n",
    "    is_connected = nx.is_connected(G)\n",
    "    print(f\"Graph is {'connected' if is_connected else 'not connected'}\")\n",
    "    if not is_connected:\n",
    "        components = list(nx.connected_components(G))\n",
    "        print(f\"Number of connected components: {len(components)}\")\n",
    "        print(f\"Sizes of connected components: {[len(c) for c in components]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting graph validation...\n",
      "Expected book count: 67651\n",
      "Actual book count: 67650\n",
      "WARNING: Mismatch in book count. Expected 67651, got 67650\n",
      "All sampled books have the required attributes.\n",
      "All sampled books are correctly connected to their authors.\n",
      "All sampled books are correctly connected to their publishers.\n",
      "All sampled books are correctly connected to their publication years.\n",
      "All sampled books are correctly connected to their formats.\n",
      "All sampled books are correctly connected to their similar books.\n",
      "All sampled books have 5 or fewer review connections.\n",
      "Graph is not connected\n",
      "Number of connected components: 8\n",
      "Sizes of connected components: [305192, 6, 7, 4, 4, 4, 5, 3]\n",
      "Graph validation complete.\n"
     ]
    }
   ],
   "source": [
    "validate_graph(G, df_1_top_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['book_id','isbn','isbn13','average_rating','ratings_count','text_reviews_count','num_pages','description',\n",
    "            'language_code','country_code','authors','publisher','publication_year','format','similar_books','Top_Reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247.40308094024658 mb\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sys.getsizeof(df_1_top_rev[col_list])/1024**2} mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.57763671875e-05 mb\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sys.getsizeof(G)/1024**2} mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving the graph\n",
    "def save_graph(G, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(G, f)\n",
    "\n",
    "# Loading the graph\n",
    "def load_graph(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the graph\n",
    "save_graph(G, '../graph-data/book_file_with_review_graph.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the graph later\n",
    "loaded_G = load_graph('../graph-data/book_file_with_review_graph.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting graph validation...\n",
      "Expected book count: 67651\n",
      "Actual book count: 67650\n",
      "WARNING: Mismatch in book count. Expected 67651, got 67650\n",
      "All sampled books have the required attributes.\n",
      "All sampled books are correctly connected to their authors.\n",
      "All sampled books are correctly connected to their publishers.\n",
      "All sampled books are correctly connected to their publication years.\n",
      "All sampled books are correctly connected to their formats.\n",
      "All sampled books are correctly connected to their similar books.\n",
      "All sampled books have 5 or fewer review connections.\n",
      "Graph is not connected\n",
      "Number of connected components: 8\n",
      "Sizes of connected components: [305192, 6, 7, 4, 4, 4, 5, 3]\n",
      "Graph validation complete.\n"
     ]
    }
   ],
   "source": [
    "validate_graph(loaded_G, df_1_top_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SouravB here!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
