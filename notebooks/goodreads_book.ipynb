{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\goodreads\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm.autonotebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"../data/file_part_1_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['isbn', 'text_reviews_count', 'series', 'country_code', 'language_code',\n",
       "       'popular_shelves', 'asin', 'is_ebook', 'average_rating', 'kindle_asin',\n",
       "       'similar_books', 'description', 'format', 'link', 'authors',\n",
       "       'publisher', 'num_pages', 'publication_day', 'isbn13',\n",
       "       'publication_month', 'edition_information', 'publication_year', 'url',\n",
       "       'image_url', 'book_id', 'ratings_count', 'work_id', 'title',\n",
       "       'title_without_series'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/book_id_review_80793.pkl','rb') as b_r:\n",
    "    book_review = pickle.load(b_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1[~df_1.description.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1[~df_1.publication_year.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1[\"book_id\"] = df_1[\"book_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_df = pd.DataFrame({\"book_id\":book_review.keys(),\"Review\":book_review.values()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_rev = pd.merge(df_1,rev_df,on=[\"book_id\"],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_rev.to_csv(\"../data/file_part_1_with_review.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_reviews(reviews, book_description, embedding_model, top_k=5):\n",
    "#     # Embed the book description\n",
    "#     book_embedding = embedding_model.encode([book_description])[0]\n",
    "    \n",
    "#     # Embed all reviews\n",
    "#     review_embeddings = embedding_model.encode(reviews)\n",
    "    \n",
    "#     # Calculate cosine similarity between book description and reviews\n",
    "#     similarities = cosine_similarity([book_embedding], review_embeddings)[0]\n",
    "    \n",
    "#     # Get indices of top-k most similar reviews\n",
    "#     top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "    \n",
    "#     # Return top-k most relevant reviews\n",
    "#     return [reviews[i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize embedding model\n",
    "# embedding_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_top_rev = pd.read_csv(\"../data/file_part_1_with_top_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  66%|██████▌   | 44697/67651 [00:43<00:18, 1215.73it/s]"
     ]
    }
   ],
   "source": [
    "for _, row in tqdm(df_1_top_rev.iterrows(), total=len(df_1_rev), desc=\"Processing rows\"):\n",
    "    G.add_node(row['book_id'], type='book', title=row['title'],\n",
    "                   isbn=row['isbn'], isbn13=row['isbn13'],\n",
    "                   average_rating=row['average_rating'],\n",
    "                   ratings_count=row['ratings_count'],\n",
    "                   text_reviews_count=row['text_reviews_count'],\n",
    "                   num_pages=row['num_pages'],\n",
    "                   description=row['description'],\n",
    "                #    language_code=row['language_code'],\n",
    "                   country_code=row['country_code'],\n",
    "                   embedding=None)\n",
    "    authors = eval(row['authors'])\n",
    "    for author in authors:\n",
    "        # print(author)\n",
    "        G.add_node(author.get('author_id'), type='author')\n",
    "        G.add_edge(row['book_id'], author.get('author_id'), relation='written_by')\n",
    "            # Add publisher node and edge\n",
    "    if pd.notna(row['publisher']):\n",
    "        G.add_node(row['publisher'], type='publisher')\n",
    "        G.add_edge(row['book_id'], row['publisher'], relation='published_by')\n",
    "    if pd.notna(row['publication_year']):\n",
    "        G.add_node(row['publication_year'], type='year')\n",
    "        G.add_edge(row['book_id'], row['publication_year'], relation='published_in_year')\n",
    "\n",
    "    # Add format node and edge\n",
    "    if pd.notna(row['format']):\n",
    "        G.add_node(row['format'], type='format')\n",
    "        G.add_edge(row['book_id'], row['format'], relation='available_in')\n",
    "        # Add similar books edges\n",
    "    if len(row['similar_books'])>0:\n",
    "        similar_books = row['similar_books']\n",
    "        for similar_book in similar_books:\n",
    "            if similar_book in df_1['book_id']:\n",
    "                G.add_edge(row['book_id'], similar_book, relation='similar_to')\n",
    "            # Process reviews\n",
    "    if 'Top_Reviews' in row:\n",
    "        try:\n",
    "            top_reviews = eval(row[\"Top_Reviews\"])\n",
    "            for i, review in enumerate(top_reviews):\n",
    "                review_node = f\"{row['book_id']}_review_{i}\"\n",
    "                G.add_node(review_node, type='review', content=review)\n",
    "                G.add_edge(row['book_id'], review_node, relation='has_review')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['book_id','isbn','isbn13','average_rating','ratings_count','text_reviews_count','num_pages','description',\n",
    "            'language_code','country_code','authors','publisher','publication_year','format','similar_books']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126.69052982330322 mb\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sys.getsizeof(df_1[col_list])/1024**2} mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.57763671875e-05 mb\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sys.getsizeof(G)/1024**2} mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Saving the graph\n",
    "def save_graph(G, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(G, f)\n",
    "\n",
    "# Loading the graph\n",
    "def load_graph(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the graph\n",
    "save_graph(G, '../graph-data/my_graph.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the graph later\n",
    "loaded_G = load_graph('../graph-data/my_graph.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.57763671875e-05 mb\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sys.getsizeof(loaded_G)/1024**2} mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "import hashlib\n",
    "\n",
    "def hash_complex_object(obj):\n",
    "    \"\"\"Create a hash for objects that are not strings or integers.\"\"\"\n",
    "    return hashlib.md5(str(obj).encode()).hexdigest()\n",
    "\n",
    "def node_to_id(node):\n",
    "    \"\"\"Convert node to a suitable id for Pyvis.\"\"\"\n",
    "    if isinstance(node, (str, int)):\n",
    "        return str(node)\n",
    "    else:\n",
    "        return hash_complex_object(node)\n",
    "\n",
    "def create_pyvis_graph(G, output_filename='pyvis_graph.html'):\n",
    "    # Create a Pyvis network\n",
    "    net = Network(notebook=True, height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "    \n",
    "    # Create a mapping of original node to its ID in the Pyvis graph\n",
    "    node_mapping = {}\n",
    "    \n",
    "    # Add nodes\n",
    "    for node, node_attrs in G.nodes(data=True):\n",
    "        node_type = node_attrs.get('type', 'unknown')\n",
    "        color = {\n",
    "            'book': '#FF6B6B',\n",
    "            'author': '#4ECDC4',\n",
    "            'publisher': '#45B7D1',\n",
    "            'year': '#FFA07A',\n",
    "            'format': '#98D8C8'\n",
    "        }.get(node_type, '#FFFFFF')\n",
    "        \n",
    "        # Convert node to a suitable id\n",
    "        node_id = node_to_id(node)\n",
    "        node_mapping[node] = node_id\n",
    "        \n",
    "        # Use a truncated version of the node id as the label if it's too long\n",
    "        label = str(node) if len(str(node)) <= 20 else str(node)[:17] + '...'\n",
    "        \n",
    "        net.add_node(node_id, label=label, title=str(node_attrs), color=color)\n",
    "    \n",
    "    # Add edges\n",
    "    for source, target, edge_attrs in G.edges(data=True):\n",
    "        source_id = node_mapping[source]\n",
    "        target_id = node_mapping[target]\n",
    "        net.add_edge(source_id, target_id, title=edge_attrs.get('relation', ''))\n",
    "    \n",
    "    # Set physics layout\n",
    "    net.force_atlas_2based()\n",
    "    \n",
    "    # Save and show the graph\n",
    "    net.show(output_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcreate_pyvis_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 41\u001b[0m, in \u001b[0;36mcreate_pyvis_graph\u001b[1;34m(G, output_filename)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# Use a truncated version of the node id as the label if it's too long\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(node) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(node)) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(node)[:\u001b[38;5;241m17\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 41\u001b[0m     \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnode_attrs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Add edges\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m source, target, edge_attrs \u001b[38;5;129;01min\u001b[39;00m G\u001b[38;5;241m.\u001b[39medges(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\goodreads\\lib\\site-packages\\pyvis\\network.py:245\u001b[0m, in \u001b[0;36mNetwork.add_node\u001b[1;34m(self, n_id, label, shape, color, **options)\u001b[0m\n\u001b[0;32m    243\u001b[0m     n \u001b[38;5;241m=\u001b[39m Node(n_id, shape, label\u001b[38;5;241m=\u001b[39mnode_label, font_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfont_color, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 245\u001b[0m     n \u001b[38;5;241m=\u001b[39m Node(n_id, shape, label\u001b[38;5;241m=\u001b[39mnode_label, color\u001b[38;5;241m=\u001b[39mcolor, font_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfont_color, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mappend(n\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_ids\u001b[38;5;241m.\u001b[39mappend(n_id)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\goodreads\\lib\\site-packages\\pyvis\\node.py:3\u001b[0m, in \u001b[0;36mNode.__init__\u001b[1;34m(self, n_id, shape, label, font_color, **opts)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mNode\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_id, shape, label, font_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts):\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions \u001b[38;5;241m=\u001b[39m opts\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m n_id\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "create_pyvis_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goodreads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
